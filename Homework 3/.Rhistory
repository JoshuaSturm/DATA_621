data = crime.training.copy)
summary(model3)
# Chunk 21: models-anova
anova(model1, model2, model3, test = "Chisq")
# Chunk 22: split-data
crime.split <- createDataPartition(y = crime.training$target, p = 0.7, list = F)
ntrain1 <- crime.training[crime.split, ]
ntest1 <- crime.training[-crime.split, ]
# Chunk 23: test-model-one
tm1 <- glm(target ~ .,
family = binomial(link = "logit"),
data = ntrain1)
tm1_prob <- predict(object = tm1, newdata = ntest1, type = "response")
tm1_p <- ifelse(tm1_prob > 0.5,1,0)
m1df <- data.frame(ntest1$target, tm1_p, tm1_prob, row.names = NULL)
names(m1df) <- c("Actual", "Predicted", "Probability")
# Chunk 24: test-model-two
ntrain2 <- crime.training[crime.split, -c(2, 3, 5, 11)]
ntest2 <- crime.training[-crime.split, -c(2, 3, 5, 11)]
tm2 <- glm(target ~ .,
family = binomial(link = "logit"),
data = ntrain2)
tm2_prob <- predict(object = tm2, newdata = ntest2, type = "response")
tm2_p <- ifelse(tm2_prob > 0.5,1,0)
m2df <- data.frame(ntest2$target, tm2_p, tm2_prob, row.names = NULL)
names(m2df) <- c("Actual", "Predicted", "Probability")
# Chunk 25: test-model-three
ntrain3 <- crime.training.copy[crime.split, -c(2, 3, 5, 9, 11)]
ntest3 <- crime.training.copy[-crime.split, -c(2, 3, 5, 9, 11)]
tm3 <- glm(target ~ .,
family = binomial(link = "logit"),
data = ntrain3)
tm3_prob <- predict(object = tm3, newdata = ntest3, type = "response")
tm3_p <- ifelse(tm3_prob > 0.5,1,0)
m3df <- data.frame(ntest3$target, tm3_p, tm3_prob, row.names = NULL)
names(m3df) <- c("Actual", "Predicted", "Probability")
# Chunk 26: metrics
pred_acc <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
acc <- (TP + TN) / (TP + TN + FP + FN)
return(acc)
}
pred_err <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
err <- (FP + FN) / (TP + TN + FP + FN)
return(err)
}
pred_prec <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
FP <- tab[3]
prec <- (TP) / (TP + FP)
return(prec)
}
pred_sens <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
FN <- tab[2]
sens <- (TP) / (TP + FN)
return(sens)
}
pred_spec <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TN <- tab[1]
FP <- tab[3]
spec <- (TN) / (TN + FP)
return(spec)
}
pred_f1 <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
prec <- (TP) / (TP + FP)
sens <- (TP) / (TP + FN)
F1 <- (2*prec*sens)/(prec+sens)
return(F1)
}
# Chunk 27: roc-formula
roc_curve <- function(dataset){
thrshld <- seq(from = 0, to = 1, by = 0.01)
# Sum totals of positives and negatives in the true column
P <- sum(dataset$Actual == 1)
N <- sum(dataset$Actual == 0)
# Ensure there's at least one of each classifier
stopifnot(P > 0, N > 0)
dataset <- arrange(dataset, desc(Probability))
# Initialize TPR, FPR, and temporary threshold vectors
tpr <- c()
fpr <- c()
tt <- integer(nrow(dataset))
for (i in 1:length(thrshld)){
tt <- ifelse(dataset$Probability > thrshld[i], 1, 0)
# Calculate Sensitivity and Specificity
TP <- sum(dataset$Actual == 1 & tt == 1)
TN <- sum(dataset$Actual == 0 & tt == 0)
FP <- sum(dataset$Actual == 0 & tt == 1)
FN <- sum(dataset$Actual == 1 & tt == 0)
sens <- (TP) / (P)
spec <- (TN) / (N)
tpr[i] <- sens
fpr[i] <- 1 - spec
}
# Store results in a dataframe
df <- data.frame(fpr, tpr)
# Calculate the area under the ROC curve
dfpr <- c(diff(df$fpr), 0)
dtpr <- c(diff(df$tpr), 0)
roc_auc <- abs(sum(tpr * dfpr) + sum(dtpr * dfpr)/2)
# Store variable for roc curve plot
roc_curve_plot <- ggplot(df, aes(x = fpr, y = tpr, ymin = 0, ymax = tpr, xmin = 0, xmax = 1)) +
geom_abline(intercept = 0, slope = 1) +
geom_point() +
geom_line() +
geom_ribbon(alpha = 0.2) +
labs(title=paste0("ROC Curve w/ AUC=", roc_auc), x = "False Positive Rate (1 - Specificity)", y = "True Positive Rate (Sensitivity)") +
annotate("text", x = 0.5, y = 0.375, label = paste("AUC = ", round(roc_auc, 4)))
roc_curve <- list(roc_curve_plot, roc_auc)
return(roc_curve)
}
# Chunk 28: results-table
c1 <- c(model1$aic, BIC(model1), model1$null.deviance - model1$deviance, pred_acc(m1df), pred_err(m1df), pred_prec(m1df), pred_sens(m1df), pred_spec(m1df), pred_f1(m1df), roc_curve(m1df)[[2]])
c2 <- c(model2$aic, BIC(model2), model2$null.deviance - model2$deviance, pred_acc(m2df), pred_err(m2df), pred_prec(m2df), pred_sens(m2df), pred_spec(m2df), pred_f1(m2df), roc_curve(m2df)[[2]])
c3 <- c(model3$aic, BIC(model3), model3$null.deviance - model3$deviance, pred_acc(m3df), pred_err(m3df), pred_prec(m3df), pred_sens(m3df), pred_spec(m3df), pred_f1(m3df), roc_curve(m3df)[[2]])
rnames <- c("AIC", "BIC", "Deviance Diff", "Accuracy", "Error Rate", "Precision", "Sensitivity", "Specificity", "F1 Score", "AUC")
# Chunk 29: metrics-table
rounded <- mapply(function(x) round(x, 4), c(c1, c2, c3))
# kable(cbind(rnames, rounded[1:10], rounded[11:20], rounded[21:30]), format = "latex", booktabs = T, col.names = c("Metric", "Model 1", "Model 2", "Model 3")) %>%
#   kable_styling(latex_options = c("striped"))
c1
# Chunk 1: setup
knitr::opts_chunk$set(echo = F, warning = F, message = F, collapse = T)
# Chunk 2: load-libraries
library(tidyverse)
library(knitr)
library(kableExtra)
library(corrplot)
library(caret)
# Chunk 3: import-data
crime <- read.csv("crime-evaluation-data_modified.csv", stringsAsFactors = F)
crime.training <- read.csv("crime-training-data_modified.csv", stringsAsFactors = F)
# Chunk 4: data-dictionary
defs <- c("proportion of residential land zoned for large lots (over 25000 square feet)",
"proportion of non-retail business   acres per suburb",
"a dummy var. for whether the suburb borders the Charles River (1) or not (0)",
"nitrogen oxides concentration (parts per 10 million)", "average number of rooms per dwelling",
"proportion of owner-occupied units built prior to 1940",
"weighted mean of distances to five Boston employment centers",
"index of accessibility to radial highways", "full-value property-tax rate per $10,000",
"pupil-teacher ratio by town", "lower status of the population (percent)",
"median value of owner-occupied homes in $1000s")
crime.dict <- data.frame(names(crime), defs, "Outcome variable", stringsAsFactors = F)
names(crime.dict) <- c("Variable Name", "Definition")
# Chunk 5: print-dictionary
kable(crime.dict, format = "latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Chunk 6: describe
crime.desc <- psych::describe(crime.training)
kable(crime.desc, format = "latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Chunk 8: summary-boxplot
crime.training.bp <- crime.training %>%
select(-target) %>%
gather()
summary.boxplot <- ggplot(crime.training.bp, aes(x = key, y = value)) +
labs(x = "variable", title = "Crime Data Training Boxplot") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
summary.boxplot
# Chunk 9: summary-histogram
crime.training.hist <- ggplot(data = crime.training.bp, mapping = aes(x = value)) +
geom_histogram(bins = 10) +
facet_wrap(~key, scales = 'free_x')
crime.training.hist
# Chunk 10: summary-correlation-heatmap
crime.training.corr <- crime.training #%>%
#select(-target) %>%
#na.omit()
corrplot(cor(crime.training.corr), method = "color", type = "lower")
# Chunk 11: summary-correlation-table
# apply(crime.training[, -13], 2, cor.test, crime.training$target)
corp <- apply(crime.training[, -13], 2, function(x) cor.test(x, y=crime.training$target)$p.value)
cortable <- cor(crime.training[, -13], crime.training$target)
kable(cbind(as.character(corp), cortable), format = "latex", booktabs = T, col.names = c("P-value", "Correlation with response")) %>%
kable_styling(latex_options = c("striped"))
# Chunk 12: variable-transformation
crime.training$chas <- as.factor(crime.training$chas)
crime.training$target <- as.factor(crime.training$target)
crime$chas <- as.factor(crime$chas)
# Chunk 13: model-one
model1 <- glm(formula = target ~ .,
family = binomial(link = "logit"),
data = crime.training)
summary(model1)
# Chunk 14: mod-one-coeff
m1coef <- round(model1$coefficients[-1], 4)
m1e <- c("More large homes would indicate a wealthier neighbourhood (unless zn is referring to apartment buildings)", "More likely to be a suburban (rather than urban) neighbourhood", "I'm not familiar with the Boston area", "Higher pollution could be due to industry or a poorly-funded area, both of which attract crime", "More rooms means a larger home, which would mean a wealthier neighbourhood", "Older units are more likely to be occupied by lower-income residents, and lower-income neighbourhoods are more likely to have crime", "Neighbourhoods farther away from employment centers have higher crime, possibly due to unemployment", "Access to highways might indicate a more urban neighbourhood, which tend to have higher crime", "This one is unclear. Higher tax rate could be due to size of unit, or overall high tax rate for that area", "Higher ratio is more likely in poorly-funded districts, which tend to have higher crime", "Lower income neighbourhoods tend to have more crime", "Surprising that neighbourhoods with higher-valued homes had more crime")
kable(cbind(m1coef, m1e), format = "latex", booktabs = T, col.names = c("Coefficient", "Possible Reasoning")) %>%
kable_styling(latex_options = c("striped"), full_width = T) %>%
column_spec(3, width = "30em")
# Chunk 15: model-one-anova
anova(model1, test = "Chisq")
# Chunk 16: model-two
model2 <- glm(formula = target ~ . -indus -chas -rm -lstat,
family = binomial(link = "logit"),
data = crime.training)
summary(model2)
# Chunk 17: mod-two-coeff
m2coef <- round(model2$coefficients[-1], 4)
m2e <- c("More large homes would indicate a wealthier neighbourhood (unless zn is referring to apartment buildings)", "Higher pollution could be due to industry or a poorly-funded area, both of which attract crime", "Older units are more likely to be occupied by lower-income residents, and lower-income neighbourhoods are more likely to have crime", "Neighbourhoods farther away from employment centers have higher crime, possibly due to unemployment", "Access to highways might indicate a more urban neighbourhood, which tend to have higher crime", "This one is unclear. Higher tax rate could be due to size of unit, or overall high tax rate for that area", "Higher ratio is more likely in poorly-funded districts, which tend to have higher crime", "Surprising that neighbourhoods with higher-valued homes had more crime")
kable(cbind(m2coef, m2e), format = "latex", booktabs = T, col.names = c("Coefficient", "Possible Reasoning")) %>%
kable_styling(latex_options = c("striped"), full_width = T) %>%
column_spec(3, width = "30em")
# Chunk 18: model-two-anova
anova(model2, test = "Chisq")
# Chunk 19: transform-zn
crime.training.copy <- crime.training[, -c(2, 3, 5, 9, 11)]
crime.training.copy$zn <- ifelse(crime.training.copy$zn == "0", 0, 1) %>%
as.factor()
# Chunk 20: model-three
model3 <- glm(formula = target ~ .,
family = binomial(link = "logit"),
data = crime.training.copy)
summary(model3)
# Chunk 21: models-anova
anova(model1, model2, model3, test = "Chisq")
# Chunk 22: split-data
crime.split <- createDataPartition(y = crime.training$target, p = 0.7, list = F)
ntrain1 <- crime.training[crime.split, ]
ntest1 <- crime.training[-crime.split, ]
# Chunk 23: test-model-one
tm1 <- glm(target ~ .,
family = binomial(link = "logit"),
data = ntrain1)
tm1_prob <- predict(object = tm1, newdata = ntest1, type = "response")
tm1_p <- ifelse(tm1_prob > 0.5,1,0)
m1df <- data.frame(ntest1$target, tm1_p, tm1_prob, row.names = NULL)
names(m1df) <- c("Actual", "Predicted", "Probability")
# Chunk 24: test-model-two
ntrain2 <- crime.training[crime.split, -c(2, 3, 5, 11)]
ntest2 <- crime.training[-crime.split, -c(2, 3, 5, 11)]
tm2 <- glm(target ~ .,
family = binomial(link = "logit"),
data = ntrain2)
tm2_prob <- predict(object = tm2, newdata = ntest2, type = "response")
tm2_p <- ifelse(tm2_prob > 0.5,1,0)
m2df <- data.frame(ntest2$target, tm2_p, tm2_prob, row.names = NULL)
names(m2df) <- c("Actual", "Predicted", "Probability")
# Chunk 25: test-model-three
ntrain3 <- crime.training.copy[crime.split, -c(2, 3, 5, 9, 11)]
ntest3 <- crime.training.copy[-crime.split, -c(2, 3, 5, 9, 11)]
tm3 <- glm(target ~ .,
family = binomial(link = "logit"),
data = ntrain3)
tm3_prob <- predict(object = tm3, newdata = ntest3, type = "response")
tm3_p <- ifelse(tm3_prob > 0.5,1,0)
m3df <- data.frame(ntest3$target, tm3_p, tm3_prob, row.names = NULL)
names(m3df) <- c("Actual", "Predicted", "Probability")
# Chunk 26: metrics
pred_acc <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
acc <- (TP + TN) / (TP + TN + FP + FN)
return(acc)
}
pred_err <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
err <- (FP + FN) / (TP + TN + FP + FN)
return(err)
}
pred_prec <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
FP <- tab[3]
prec <- (TP) / (TP + FP)
return(prec)
}
pred_sens <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
FN <- tab[2]
sens <- (TP) / (TP + FN)
return(sens)
}
pred_spec <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TN <- tab[1]
FP <- tab[3]
spec <- (TN) / (TN + FP)
return(spec)
}
pred_f1 <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
prec <- (TP) / (TP + FP)
sens <- (TP) / (TP + FN)
F1 <- (2*prec*sens)/(prec+sens)
return(F1)
}
# Chunk 27: roc-formula
roc_curve <- function(dataset){
thrshld <- seq(from = 0, to = 1, by = 0.01)
# Sum totals of positives and negatives in the true column
P <- sum(dataset$Actual == 1)
N <- sum(dataset$Actual == 0)
# Ensure there's at least one of each classifier
stopifnot(P > 0, N > 0)
dataset <- arrange(dataset, desc(Probability))
# Initialize TPR, FPR, and temporary threshold vectors
tpr <- c()
fpr <- c()
tt <- integer(nrow(dataset))
for (i in 1:length(thrshld)){
tt <- ifelse(dataset$Probability > thrshld[i], 1, 0)
# Calculate Sensitivity and Specificity
TP <- sum(dataset$Actual == 1 & tt == 1)
TN <- sum(dataset$Actual == 0 & tt == 0)
FP <- sum(dataset$Actual == 0 & tt == 1)
FN <- sum(dataset$Actual == 1 & tt == 0)
sens <- (TP) / (P)
spec <- (TN) / (N)
tpr[i] <- sens
fpr[i] <- 1 - spec
}
# Store results in a dataframe
df <- data.frame(fpr, tpr)
# Calculate the area under the ROC curve
dfpr <- c(diff(df$fpr), 0)
dtpr <- c(diff(df$tpr), 0)
roc_auc <- abs(sum(tpr * dfpr) + sum(dtpr * dfpr)/2)
# Store variable for roc curve plot
roc_curve_plot <- ggplot(df, aes(x = fpr, y = tpr, ymin = 0, ymax = tpr, xmin = 0, xmax = 1)) +
geom_abline(intercept = 0, slope = 1) +
geom_point() +
geom_line() +
geom_ribbon(alpha = 0.2) +
labs(title=paste0("ROC Curve w/ AUC=", roc_auc), x = "False Positive Rate (1 - Specificity)", y = "True Positive Rate (Sensitivity)") +
annotate("text", x = 0.5, y = 0.375, label = paste("AUC = ", round(roc_auc, 4)))
roc_curve <- list(roc_curve_plot, roc_auc)
return(roc_curve)
}
# Chunk 28: results-table
c1 <- c(model1$aic, BIC(model1), model1$null.deviance - model1$deviance, pred_acc(m1df), pred_err(m1df), pred_prec(m1df), pred_sens(m1df), pred_spec(m1df), pred_f1(m1df), roc_curve(m1df)[[2]])
c2 <- c(model2$aic, BIC(model2), model2$null.deviance - model2$deviance, pred_acc(m2df), pred_err(m2df), pred_prec(m2df), pred_sens(m2df), pred_spec(m2df), pred_f1(m2df), roc_curve(m2df)[[2]])
c3 <- c(model3$aic, BIC(model3), model3$null.deviance - model3$deviance, pred_acc(m3df), pred_err(m3df), pred_prec(m3df), pred_sens(m3df), pred_spec(m3df), pred_f1(m3df), roc_curve(m3df)[[2]])
rnames <- c("AIC", "BIC", "Deviance Diff", "Accuracy", "Error Rate", "Precision", "Sensitivity", "Specificity", "F1 Score", "AUC")
# Chunk 29: metrics-table
rounded <- mapply(function(x) round(x, 4), c(c1, c2, c3))
# kable(cbind(rnames, rounded[1:10], rounded[11:20], rounded[21:30]), format = "latex", booktabs = T, col.names = c("Metric", "Model 1", "Model 2", "Model 3")) %>%
#   kable_styling(latex_options = c("striped"))
c1
roc_curve(model1)[[1]]
roc_curve(m1df)[[1]]
roc_curvep1
roc_curve(m1df)[1]
test <- roc_curve(m1df)
View(test)
unlist(test)
unlist(test[[1]])
unlist(test[1])
View(cortable)
View(crime)
View(crime)
eval <- crime[, -c(2, 3, 5, 11)]
View(tm3)
eval$prob <- predict(object = tm2, newdata = eval, type = "response")
View(eval)
eval <- crime[, -c(2, 3, 5, 11)]
eval$Probability <- predict(object = tm2, newdata = eval, type = "response")
eval$Predicted <- ifelse(eval$Probability > 0.5,1,0)
View(eval)
summary(eval$Probability)
eval <- crime[, -c(2, 3, 5, 11)]
eval$Probability <- predict(object = model2, newdata = eval, type = "response")
eval$Predicted <- ifelse(eval$Probability > 0.5,1,0)
eval <- crime[, -c(2, 3, 5, 11)]
eval$Probability <- predict(object = model2, newdata = eval, type = "response")
eval$Predicted <- ifelse(eval$Probability > 0.5,1,0)
eval <- crime[, -c(2, 3, 5, 11)]
eval$Probability <- predict(object = model2, newdata = eval, type = "response")
View(crime)
View(eval)
View(model2)
model2
eval <- crime[, -c(2, 3, 5, 11)]
model <- glm(formula = target ~ ., family = binomial(link = "logit"),
data = crime.training[, -c(2, 3, 5, 11)])
eval$Probability <- predict(object = model, newdata = eval, type = "response")
eval$Predicted <- ifelse(eval$Probability > 0.5,1,0)
View(eval)
summary(eval$Probability)
View(crime.training)
View(crime)
eval[, c(Probability, Predicted)]
eval[, c("Probability", "Predicted")]
kable(eval)
kable(eval, format = "latex", booktabs = T) %>%
kable_styling(latex_options = c("striped"))
