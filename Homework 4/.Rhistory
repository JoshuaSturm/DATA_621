lapply(str_replace_all, pattern = "z_", replacement = "") %>%
lapply(str_replace_all, pattern = ",", replacement = "") %>%
lapply(str_replace_all, "<", "No ")
# Chunk 9
ins.training$URBANICITY <- ifelse(ins.training$URBANICITY == "Highly Urban/ Urban", "Urban", "Rural")
ins.evaluation$URBANICITY <- ifelse(ins.evaluation$URBANICITY == "Highly Urban/ Urban", "Urban", "Rural")
# Chunk 10: recode-variables
ins.training[, c(1, 2, 7:10, 12, 14:17, 19:22, 25)] <- mutate_all(ins.training[, c(1, 2, 7:10, 12, 14:17, 19:22, 25)], funs(as.factor))
ins.training[, c(3:6, 11, 13, 18, 23:24, 26)] <- mutate_all(ins.training[, c(3:6, 11, 13, 18, 23:24, 26)], funs(as.numeric))
# Repeat for evaluation data
ins.evaluation[, c(1, 2, 7:10, 12, 14:17, 19:22, 25)] <- mutate_all(ins.evaluation[, c(1, 2, 7:10, 12, 14:17, 19:22, 25)], funs(as.factor))
ins.evaluation[, c(3:6, 11, 13, 18, 23:24, 26)] <- mutate_all(ins.evaluation[, c(3:6, 11, 13, 18, 23:24, 26)], funs(as.numeric))
# Chunk 11: summary-boxplot
ins.bp1 <- ins.training %>%
select(c(4, 6, 23, 24, 26)) %>%
gather()
summary.boxplot1 <- ggplot(ins.bp1, aes(x = key, y = value)) +
labs(x = "variable", title = "Insurance Data Boxplot") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
summary.boxplot1
#
ins.bp2 <- ins.training %>%
select(c(3, 5, 11, 13, 18)) %>%
gather()
summary.boxplot2 <- ggplot(ins.bp2, aes(x = key, y = value)) +
labs(x = "variable", title = "Insurance Data Boxplot") +
geom_boxplot(outlier.colour = "red", outlier.shape = 1)
summary.boxplot2
# Chunk 12: summary-histogram
ins.h <- ins.training %>%
select(c(4:6, 11, 13, 18, 23:24, 26)) %>%
gather()
ins.hist <- ggplot(data = ins.h, mapping = aes(x = value)) +
geom_histogram(bins = 10) +
facet_wrap(~key, scales = 'free_x')
ins.hist
# Chunk 13: summary-bar
ins.b <- ins.training %>%
select(c(7:10, 12, 14:17, 19:22, 25)) %>%
gather()
ins.bar <- ggplot(data = ins.b, mapping = aes(x = value)) +
geom_bar() +
facet_wrap(~key, scales = 'free_x')
ins.bar
# Chunk 14: summary-correlation-heatmap
ins.c <- mutate_all(ins.training, funs(as.numeric)) %>%
na.omit(.)
corrplot(cor(ins.c), method = "color", type = "lower")
# Chunk 15: summary-correlation-tables
# TARGET_FLAG
corp1 <- apply(ins.c[, -c(1:3)], 2, function(x) cor.test(x, y=ins.c$TARGET_FLAG)$p.value)
cortable1 <- cor(ins.c[, -c(1:3)], ins.c$TARGET_FLAG)
#TARGET_AMT
corp2 <- apply(ins.c[, -c(1:3)], 2, function(x) cor.test(x, y=ins.c$TARGET_AMT)$p.value)
cortable2 <- cor(ins.c[, -c(1:3)], ins.c$TARGET_AMT)
lt1 <- cbind(as.character(corp1), cortable1)
lt2 <- cbind(as.character(corp2), cortable2)
colnames(lt1) <- c("P-Value", "Correlation With Response")
colnames(lt2) <- c("P-Value", "Correlation With Response")
kable(cbind(lt1,lt2), format = "latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down")) %>%
add_header_above(c(" ", "TARGET_FLAG" = 2, "TARGET_AMT" = 2))
# Chunk 16: impute-age
ins.training$CAR_AGE[ins.training$CAR_AGE == -3] <- abs(-3)
insz <- ins.training[, -1]
insrf <- ins.training[, -1]
insz$AGE[is.na(insz$AGE)] <- median(insz$AGE, na.rm = T)
insrf$AGE[is.na(insrf$AGE)] <- median(insrf$AGE, na.rm = T)
# Chunk 17: imputation-to-zero
insz$HOME_VAL[is.na(insz$HOME_VAL)] <- 0
insz$INCOME[is.na(insz$INCOME)] <- 0
# Chunk 18: imputation-random-forest
# cores = detectCores() - 1
# registerDoParallel(cores = cores)
# insrf1 <- missForest(xmis = insrf,
#                      maxiter = 10,
#                      ntree = 100,
#                      variablewise = T,
#                      verbose = T,
#                      parallelize = "forests")
# registerDoParallel(cores = cores)
# insz <- missForest(xmis = insz,
#                      maxiter = 10,
#                      ntree = 100,
#                      variablewise = T,
#                      verbose = T,
#                      parallelize = "forests")
# Write results to csv as a backup
# write.csv(insrf1$ximp, "imputedData.csv")
# write.csv(insz$ximp, "zeroImputedData.csv")
insrf <- read.csv("./data/imputedData.csv")
insz <- read.csv("./data/zeroImputedData.csv")
# Chunk 19: transform-carage
insz$CAR_AGE <- ifelse(insz$CAR_AGE > 1, 0, 1)
colnames(insz)[colnames(insz) == "CAR_AGE"] <- "NEW_CAR"
insrf$CAR_AGE <- ifelse(insrf$CAR_AGE > 1, 0, 1)
colnames(insrf)[colnames(insrf) == "CAR_AGE"] <- "NEW_CAR"
ins.evaluation$CAR_AGE <- ifelse(ins.evaluation$CAR_AGE > 1, 0, 1)
colnames(ins.evaluation)[colnames(ins.evaluation) == "CAR_AGE"] <- "NEW_CAR"
# Chunk 20: log-model-one
logmodel1 <- glm(formula = TARGET_FLAG ~ . -INDEX -TARGET_AMT,
family = binomial(link = "logit"),
data = ins.training)
summary(logmodel1)
# Chunk 21: anova-log-model-one
anova(logmodel1, test = "Chisq")
# Chunk 22: log-model-two
logmodel2 <- glm(formula = TARGET_FLAG ~ . -TARGET_AMT,
family = binomial(link = "logit"),
data = insz)
summary(logmodel2)
# Chunk 23: anova-log-model-two
anova(logmodel2, test = "Chisq")
# Chunk 24: log-model-three
logmodel3 <- glm(formula = TARGET_FLAG ~ . -TARGET_AMT,
family = binomial(link = "logit"),
data = insrf)
summary(logmodel3)
# Chunk 25: anova-log-model-three
anova(logmodel3, test = "Chisq")
# Chunk 26: linear-model-one
lmodel1 <- lm(formula = TARGET_AMT ~ . -INDEX -TARGET_FLAG,
data = ins.training)
summary(lmodel1)
gvlma(lmodel1)
# Chunk 27: linear-model-two
insz <- insz %>%
select(-X)
lmodel2 <- lm(formula = TARGET_AMT ~ . -TARGET_FLAG,
data = insz)
summary(lmodel2)
gvlma(lmodel2)
# Chunk 28: linear-model-three
lmodel3 <- lm(formula = TARGET_AMT ~ . -TARGET_FLAG,
data = insrf)
summary(lmodel3)
gvlma(lmodel3)
# Chunk 29: test-linear-model
summary(lm(formula = TARGET_AMT ~ . -TARGET_FLAG,
data = insrf[-c(7072, 5389, 7691, 7780), ])
)
# Chunk 30: transform-evaluation
ins.evaluation$AGE[is.na(ins.evaluation$AGE)] <- median(ins.evaluation$AGE, na.rm = T)
ins.evaluation$HOME_VAL[is.na(ins.evaluation$HOME_VAL)] <- 0
ins.evaluation$INCOME[is.na(ins.evaluation$INCOME)] <- 0
ins.evaluation <- ins.evaluation[, -1]
cores = detectCores() - 1
registerDoParallel(cores = cores)
ins.eval1 <- missForest(xmis = ins.evaluation,
maxiter = 10,
ntree = 100,
variablewise = T,
verbose = T,
parallelize = "forests")
write.csv(ins.eval1$ximp, "./data/evalImputed.csv")
inse <- read.csv("./data/evalImputed.csv")
inse %<>%
select(-X) %>%
mutate(TARGET_AMT = 0, TARGET_FLAG = 0)
predicted.amt <- predict(object = lmodel2,
newdata = inse,
type = "response")
rp1 <- ggplot(lmodel2, aes(.fitted, .resid)) +
geom_point() +
geom_hline(yintercept = 0) +
geom_smooth(se = FALSE) +
labs(title = "Residuals vs Fitted")
rp2 <- ggplot(lmodel2, aes(.fitted, .stdresid)) +
geom_point() +
geom_hline(yintercept = 0) +
geom_smooth(se = FALSE)
rp3 <- ggplot(lmodel2) +
stat_qq(aes(sample = .stdresid)) +
geom_abline()
rp4 <- ggplot(lmodel2, aes(.fitted, sqrt(abs(.stdresid)))) +
geom_point() +
geom_smooth(se = FALSE) +
labs(title = "Scale-Location")
rp5 <- ggplot(lmodel2, aes(seq_along(.cooksd), .cooksd)) +
geom_col() +
ylim(0, 0.0075) +
labs(title = "Cook's Distance")
rp6 <- ggplot(lmodel2, aes(.hat, .stdresid)) +
geom_point(aes(size = .cooksd)) +
geom_smooth(se = FALSE, size = 0.5) +
labs(title = "Residuals vs Leverage")
rp7 <- ggplot(lmodel2, aes(.hat, .cooksd)) +
geom_vline(xintercept = 0, colour = NA) +
geom_abline(slope = seq(0, 3, by = 0.5), colour = "white") +
geom_smooth(se = FALSE) +
geom_point() +
labs(title = "Cook's distance vs Leverage")
rp8 <- ggplot(lmodel2, aes(.resid)) +
geom_histogram(bins = 7, color="darkblue", fill="steelblue")
grid.arrange(rp1, rp2, rp3, rp4, rp5, rp6, rp7, rp8, ncol = 2)
View(ins.evaluation)
predicted.flag <- predict(object = logmodel2,
newdata = inse,
type = "response")
View(lmodel2)
View(inse)
View(insz)
set.seed(22)
# Split data into training and testing partitions
train <- insz %>%
sample_frac(., size = 0.7, replace = F)
test <- anti_join(insz, train)
logpred <- glm(TARGET_FLAG ~ . - TARGET_AMT,
family = binomial(link = "logit"),
data = train)
log_prob <- predict(object = logpred, newdata = test, type = "response")
log_p <- ifelse(log_prob > 0.5,1,0)
logpred <- glm(TARGET_FLAG ~ . - TARGET_AMT,
family = binomial(link = "logit"),
data = train)
log_prob <- predict(object = logpred, newdata = test, type = "response")
log_p <- ifelse(log_prob > 0.5,1,0)
logpdf <- data.frame(test$TARGET_FLAG, log_p, log_prob, row.names = NULL)
names(logpdf) <- c("Actual", "Predicted", "Probability")
View(logpdf)
View(logpred)
View(logpdf)
pred_acc <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
acc <- (TP + TN) / (TP + TN + FP + FN)
return(acc)
}
pred_err <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
err <- (FP + FN) / (TP + TN + FP + FN)
return(err)
}
pred_prec <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
FP <- tab[3]
prec <- (TP) / (TP + FP)
return(prec)
}
pred_sens <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
FN <- tab[2]
sens <- (TP) / (TP + FN)
return(sens)
}
pred_spec <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TN <- tab[1]
FP <- tab[3]
spec <- (TN) / (TN + FP)
return(spec)
}
pred_f1 <- function(dataset){
# Check if entered dataset is a dataframe; if not, cooerce it to one
if (!(is.data.frame(dataset))){
dataset <- as.data.frame(dataset)
}
# Ensure dataframe is not empty
if (is_empty(dataset)){
stop("You've entered an empty dataset!")
}
tab <- table(dataset$Actual, dataset$Predicted)
TP <- tab[4]
TN <- tab[1]
FP <- tab[3]
FN <- tab[2]
prec <- (TP) / (TP + FP)
sens <- (TP) / (TP + FN)
F1 <- (2*prec*sens)/(prec+sens)
return(F1)
}
roc_curve <- function(dataset){
thrshld <- seq(from = 0, to = 1, by = 0.01)
# Sum totals of positives and negatives in the true column
P <- sum(dataset$Actual == 1)
N <- sum(dataset$Actual == 0)
# Ensure there's at least one of each classifier
stopifnot(P > 0, N > 0)
dataset <- arrange(dataset, desc(Probability))
# Initialize TPR, FPR, and temporary threshold vectors
tpr <- c()
fpr <- c()
tt <- integer(nrow(dataset))
for (i in 1:length(thrshld)){
tt <- ifelse(dataset$Probability > thrshld[i], 1, 0)
# Calculate Sensitivity and Specificity
TP <- sum(dataset$Actual == 1 & tt == 1)
TN <- sum(dataset$Actual == 0 & tt == 0)
FP <- sum(dataset$Actual == 0 & tt == 1)
FN <- sum(dataset$Actual == 1 & tt == 0)
sens <- (TP) / (P)
spec <- (TN) / (N)
tpr[i] <- sens
fpr[i] <- 1 - spec
}
# Store results in a dataframe
df <- data.frame(fpr, tpr)
# Calculate the area under the ROC curve
dfpr <- c(diff(df$fpr), 0)
dtpr <- c(diff(df$tpr), 0)
roc_auc <- abs(sum(tpr * dfpr) + sum(dtpr * dfpr)/2)
# Store variable for roc curve plot
roc_curve_plot <- ggplot(df, aes(x = fpr, y = tpr, ymin = 0, ymax = tpr, xmin = 0, xmax = 1)) +
geom_abline(intercept = 0, slope = 1) +
geom_point() +
geom_line() +
geom_ribbon(alpha = 0.2) +
labs(title=paste0("ROC Curve w/ AUC=", roc_auc), x = "False Positive Rate (1 - Specificity)", y = "True Positive Rate (Sensitivity)") +
annotate("text", x = 0.5, y = 0.375, label = paste("AUC = ", round(roc_auc, 4)))
roc_curve <- list(roc_curve_plot, roc_auc)
return(roc_curve)
}
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpred), pred_err(logpred), pred_prec(logpred), pred_sens(logpred), pred_spec(logpred), pred_f1(logpred), roc_curve(logpred)[[2]])
rnames <- c("AIC", "BIC", "Deviance Diff", "Accuracy", "Error Rate", "Precision", "Sensitivity", "Specificity", "F1 Score", "AUC")
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpred), pred_err(logpred), pred_prec(logpred), pred_sens(logpred), pred_spec(logpred), pred_f1(logpred), roc_curve(logpred)[[2]])
rnames <- c("AIC", "BIC", "Deviance Diff", "Accuracy", "Error Rate", "Precision", "Sensitivity", "Specificity", "F1 Score", "AUC")
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpred), pred_err(logpred), pred_prec(logpred), pred_sens(logpred), pred_spec(logpred), pred_f1(logpred), roc_curve(logpred)[[2]])
## 4.3 Logistic Prediction
```{r log-pred}
logpred <- glm(TARGET_FLAG ~ . -TARGET_AMT,
family = binomial(link = "logit"),
data = train)
log_prob <- predict(object = logpred, newdata = test, type = "response")
log_p <- ifelse(log_prob > 0.5,1,0)
logpdf <- data.frame(test$TARGET_FLAG, log_p, log_prob, row.names = NULL)
names(logpdf) <- c("Actual", "Predicted", "Probability")
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpred), pred_err(logpred), pred_prec(logpred), pred_sens(logpred), pred_spec(logpred), pred_f1(logpred), roc_curve(logpred)[[2]])
logpred$aic
BIC(logpred)
logpred$null.deviance - logpred$deviance
pred_acc(logpred)
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpdf), pred_err(logpdf), pred_prec(logpdf), pred_sens(logpdf), pred_spec(logpdf), pred_f1(logpdf), roc_curve(logpred)[[2]])
rnames <- c("AIC", "BIC", "Deviance Diff", "Accuracy", "Error Rate", "Precision", "Sensitivity", "Specificity", "F1 Score", "AUC")
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpdf), pred_err(logpdf), pred_prec(logpdf), pred_sens(logpdf), pred_spec(logpdf), pred_f1(logpdf), roc_curve(logpred)[[2]])
View(logpdf)
roc_curve(logpdf)
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpdf), pred_err(logpdf), pred_prec(logpdf), pred_sens(logpdf), pred_spec(logpdf), pred_f1(logpdf), roc_curve(logpdf)[[2]])
rnames <- c("AIC", "BIC", "Deviance Diff", "Accuracy", "Error Rate", "Precision", "Sensitivity", "Specificity", "F1 Score", "AUC")
round(logpredr, 4)
logpredr <- round(logpredr, 4)
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpdf), pred_err(logpdf), pred_prec(logpdf), pred_sens(logpdf), pred_spec(logpdf), pred_f1(logpdf), roc_curve(logpdf)[[2]])
kable(round(logpredr, 4), format = "latex", booktabs = T, col.names = c("Metric", "Model 1")) %>%
kable_styling(latex_options = c("striped"))
kable(round(logpredr, 4), format = "latex", booktabs = T, col.names = c("Metric")) %>%
kable_styling(latex_options = c("striped"))
insz$CAR_AGE <- ifelse(insz$CAR_AGE > 1, 0, 1)
colnames(insz)[colnames(insz) == "CAR_AGE"] <- "NEW_CAR"
insrf$CAR_AGE <- ifelse(insrf$CAR_AGE > 1, 0, 1)
colnames(insrf)[colnames(insrf) == "CAR_AGE"] <- "NEW_CAR"
ins.evaluation$CAR_AGE <- ifelse(ins.evaluation$CAR_AGE > 1, 0, 1)
colnames(ins.evaluation)[colnames(ins.evaluation) == "CAR_AGE"] <- "NEW_CAR"
View(insz)
insz <- read.csv("./data/zeroImputedData.csv")
View(insz)
View(ins.evaluation)
View(insrf)
logpredr <- c(logpred$aic, BIC(logpred), logpred$null.deviance - logpred$deviance, pred_acc(logpdf), pred_err(logpdf), pred_prec(logpdf), pred_sens(logpdf), pred_spec(logpdf), pred_f1(logpdf), roc_curve(logpdf)[[2]])
rnames <- c("AIC", "BIC", "Deviance Diff", "Accuracy", "Error Rate", "Precision", "Sensitivity", "Specificity", "F1 Score", "AUC")
kable(cbind(rnames, round(logpredr, 4)), format = "latex", booktabs = T, col.names = c("Metric", "Model Results")) %>%
kable_styling(latex_options = c("striped"))
linpred <- lm(formula = TARGET_AMT ~ . -TARGET_FLAG,
data = train)
lin_prob <- predict(object = linpred, newdata = test, type = "response")
lresults.df <- data.frame(cbind(actuals = test$TARGET_AMT, predicted = lin_prob))
View(lresults.df)
View(train)
View(test)
linpred <- lm(formula = TARGET_AMT ~ . -TARGET_FLAG,
data = train)
lin_prob <- predict(object = linpred, newdata = test, type = "response")
lresults.df <- data.frame(cbind(actuals = test$TARGET_AMT, predicted = lin_prob))
lresults.df <- lresults.df %>%
mutate(error = lresults.df$actuals - lresults.df$predicted) %>%
round(., 2)
lresults.df <- lresults.df %>%
mutate(percerror = paste0(round(lresults.df$error/lresults.df$actuals*100,2),"%"))
kable(head(lresults.df))
sprintf("The mean percent error is: %s%%", round(mean(lresults.df$error/lresults.df$actuals*100), 2))
sprintf("The mean percent error is: %s%%", round(mean(lresults.df$error/lresults.df$actuals*100, na.rm = T), 2))
sprintf("The mean percent error is: %s%%", round(mean(lresults.df$error/lresults.df$actuals*100, na.exclude()), 2))
sprintf("The mean percent error is: %s%%", round(mean(na.exclude(lresults.df$error/lresults.df$actuals*100)), 2))
inse %<>%
select(-X) %>%
mutate(TARGET_AMT = 0, TARGET_FLAG = 0)
elim <- predict(object = lmodel2,
newdata = inse,
type = "response")
elom <- predict(object = logmodel2,
newdata = inse,
type = "response")
View(inse)
View(lmodel2)
# cores = detectCores() - 1
#
# registerDoParallel(cores = cores)
# ins.eval1 <- missForest(xmis = ins.evaluation,
#                         maxiter = 10,
#                         ntree = 100,
#                         variablewise = T,
#                         verbose = T,
#                         parallelize = "forests")
# write.csv(ins.eval1$ximp, "./data/evalImputed.csv")
inse <- read.csv("./data/evalImputed.csv")
View(inse)
inse %<>%
select(-X) %>%
mutate(TARGET_AMT = 0, TARGET_FLAG = 0)
elim <- predict(object = lmodel2,
newdata = inse,
type = "response")
elom <- predict(object = logmodel2,
newdata = inse,
type = "response")
insz <- insz %>%
select(-X)
logmodel2 <- glm(formula = TARGET_FLAG ~ . -TARGET_AMT,
family = binomial(link = "logit"),
data = insz)
summary(logmodel2)
inse %<>%
select(-X) %>%
mutate(TARGET_AMT = 0, TARGET_FLAG = 0)
elim <- predict(object = lmodel2,
newdata = inse,
type = "response")
elom <- predict(object = logmodel2,
newdata = inse,
type = "response")
?try
inse %<>%
mutate(TARGET_AMT = 0, TARGET_FLAG = 0) %>%
try(select(-X), T)
View(inse)
inse %<>%
mutate(TARGET_AMT = 0, TARGET_FLAG = 0) %>%
try(select(-X), T)
elim <- predict(object = lmodel2,
newdata = inse,
type = "response")
elom <- predict(object = logmodel2,
newdata = inse,
type = "response")
eldf <- data.frame(Predicted_FLAG = elom, Predicted_AMT = elim)
View(eldf)
inse %<>%
mutate(TARGET_AMT = 0, TARGET_FLAG = 0) %>%
try(select(-X), T)
elim <- predict(object = lmodel2,
newdata = inse,
type = "response")
elom <- predict(object = logmodel2,
newdata = inse,
type = "response")
eldf <- data.frame(Predicted_FLAG_prob = elom, Predicted_AMT = elim)
eldf$Predicted_Flag <- ifelse(eldf$elom > 0.5,1,0)
eldf$Predicted_Flag <- ifelse(eldf$elom > 0.5,1,0)
eldf <- data.frame(Predicted_FLAG_prob = elom, Predicted_AMT = elim)
View(eldf)
eldf <- data.frame(Predicted_FLAG_prob = elom, Predicted_AMT = elim) %>%
mutate(Predicted_Flag = ifelse(eldf$elom > 0.5,1,0))
eldf <- data.frame(Predicted_FLAG_prob = elom, Predicted_AMT = elim) %>%
mutate(Predicted_Flag = ifelse(Predicted_FLAG_prob > 0.5,1,0))
View(eldf)
